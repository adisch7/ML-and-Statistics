import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm
import statsmodels.formula.api as smf
import statsmodels.genmod as gm

'''Multiple regression S1-Up'''

# # Sample data creation for demonstration (remove this section if you have the actual data)
# np.random.seed(0)
# routes_cover_s1 = pd.DataFrame({
#     'TreesCover': np.random.normal(size=100),
#     'BuildingsCover': np.random.normal(size=100),
#     'BusinessCover': np.random.normal(size=100),
#     'CemeteryCover': np.random.normal(size=100),
#     'IndustrialCover': np.random.normal(size=100),
#     'InfrastructureCover': np.random.normal(size=100),
#     'ParksCover': np.random.normal(size=100),
#     'PublicInstitutionCover': np.random.normal(size=100),
#     'ResidenceCover': np.random.normal(size=100),
#     'SportsCover': np.random.normal(size=100),
#     'NearestJlmPoleDistance': np.random.normal(size=100),
#     'Classification': np.random.choice(['HPS', 'LED'], size=100),
#     'RoadsHierarchy': np.random.choice(['motorway', 'trunk', 'primary', 'secondary', 'tertiary', 'residential'], size=100),
#     'lux_log10': np.random.poisson(lam=10, size=100)
# })

# One-hot encoding of categorical variables
routes_cover_s1_encoded = pd.get_dummies(routes_cover_s1, columns=['Classification', 'RoadsHierarchy'])

# Define the model formula
# Note: The categorical variables are now 'Classification_HPS', 'Classification_LED', 'RoadsHierarchy_motorway', 'RoadsHierarchy_primary', 'RoadsHierarchy_residential', 'RoadsHierarchy_secondary', 'RoadsHierarchy_tertiary', 'RoadsHierarchy_trunk' after one-hot encoding
formula = 'lux_log10 ~ TreesCover + BuildingsCover + BusinessCover + CemeteryCover + IndustrialCover + InfrastructureCover + ParksCover + PublicInstitutionCover + ResidenceCover + SportsCover + NearestJlmPoleDistance + Classification_HPS + Classification_LED + RoadsHierarchy_motorway + RoadsHierarchy_primary + RoadsHierarchy_residential + RoadsHierarchy_secondary + RoadsHierarchy_tertiary + RoadsHierarchy_trunk'

# Fit the model
model = smf.glm(formula=formula, data=routes_cover_s1_encoded, family=sm.families.Gaussian())
result = model.fit()

# Print the summary
print(result.summary())

# Calculate McFadden's pseudo R-squared
llf = result.llf  # Log-likelihood of the fitted model
llnull = result.llnull  # Log-likelihood of the null model
pseudo_r2 = 1 - llf / llnull

# Calculate the regular R-squared
y = routes_cover_s1_encoded['lux_log10']
y_pred = result.predict(routes_cover_s1_encoded)
ss_res = np.sum((y - y_pred) ** 2)
ss_tot = np.sum((y - np.mean(y)) ** 2)
r_squared = 1 - (ss_res / ss_tot)

# Predict the values
routes_cover_s1_encoded['predicted'] = y_pred

lux_log10_seq = np.linspace(routes_cover_s1_encoded['lux_log10'].min(), routes_cover_s1_encoded['lux_log10'].max(), num=100)
regression_data = pd.DataFrame({
    'lux_log10': lux_log10_seq,
    'TreesCover': np.mean(routes_cover_s1_encoded['TreesCover']),
    'BuildingsCover': np.mean(routes_cover_s1_encoded['BuildingsCover']),
    'BusinessCover': np.mean(routes_cover_s1_encoded['BusinessCover']),
    'CemeteryCover': np.mean(routes_cover_s1_encoded['CemeteryCover']),
    'IndustrialCover': np.mean(routes_cover_s1_encoded['IndustrialCover']),
    'InfrastructureCover': np.mean(routes_cover_s1_encoded['InfrastructureCover']),
    'ParksCover': np.mean(routes_cover_s1_encoded['ParksCover']),
    'PublicInstitutionCover': np.mean(routes_cover_s1_encoded['PublicInstitutionCover']),
    'ResidenceCover': np.mean(routes_cover_s1_encoded['ResidenceCover']),
    'SportsCover': np.mean(routes_cover_s1_encoded['SportsCover']),
    'NearestJlmPoleDistance': np.mean(routes_cover_s1_encoded['NearestJlmPoleDistance']),
    'Classification_HPS': np.mean(routes_cover_s1_encoded['Classification_HPS']),
    'Classification_LED': np.mean(routes_cover_s1_encoded['Classification_LED']),
    'RoadsHierarchy_motorway': np.mean(routes_cover_s1_encoded['RoadsHierarchy_motorway']),
    'RoadsHierarchy_primary': np.mean(routes_cover_s1_encoded['RoadsHierarchy_primary']),
    'RoadsHierarchy_residential': np.mean(routes_cover_s1_encoded['RoadsHierarchy_residential']),
    'RoadsHierarchy_secondary': np.mean(routes_cover_s1_encoded['RoadsHierarchy_secondary']),
    'RoadsHierarchy_tertiary': np.mean(routes_cover_s1_encoded['RoadsHierarchy_tertiary']),
    'RoadsHierarchy_trunk': np.mean(routes_cover_s1_encoded['RoadsHierarchy_trunk'])
})

regression_line = result.predict(regression_data)

# Plot the actual vs. predicted values
plt.figure(figsize=(10, 6))
#plt.scatter(routes_cover_s1_encoded['lux_log10'], routes_cover_s1_encoded['lux_log10'], color='blue', label='Actual Values')
#plt.scatter(routes_cover_s1_encoded['lux_log10'], routes_cover_s1_encoded['predicted'], color='red', label='Predicted Values')
plt.scatter(routes_cover_s1_encoded['lux_log10'], routes_cover_s1_encoded['predicted'])
#plt.plot(lux_log10_seq, regression_line, color='#C6C009', label='Regression Line')
plt.xlabel('Actual Light intense (lux [log10])')
plt.ylabel('Predicted Light intense (lux [log10])')
a, b = np.polyfit(routes_cover_s1_encoded['lux_log10'], routes_cover_s1_encoded['predicted'], 1)
plt.plot(routes_cover_s1_encoded['lux_log10'], a*routes_cover_s1_encoded['lux_log10']+b, color='#C6C009', label='Regression Line')

#plt.legend()

# Add R-squared to the plot
plt.text(0.05, 0.95, f'McFadden\'s R^2: {pseudo_r2:.4f}', transform=plt.gca().transAxes, 
         fontsize=12, verticalalignment='top', horizontalalignment='left')

plt.title('GLM Gaussian Regression on S1: Actual vs Predicted Values with R^2')
plt.grid()
plt.show()
#plt.savefig('Multiple regression S1.png', dpi=300)

'''Validate second option'''
# Coefficient plot with Standardized Coefficient

# Read the CSV file
coefficient_df2 = pd.read_csv(r'C:\Users\Adi\OneDrive\Documents\LP\Thesis\R table2 for Noam_production version.csv')

# Convert specified columns to numeric, coercing errors to NaN
columns_to_convert = ['S1', 'S2+S4', 'S3+S5', 'S1+S2+S3+S4+S5']
coefficient_df2[columns_to_convert] = coefficient_df2[columns_to_convert].apply(pd.to_numeric, errors='coerce')

# Standardize coefficients
standardized_df = coefficient_df2[columns_to_convert].apply(lambda x: (x - x.mean()) / x.std(), axis=0)

# Define the new index
new_index = [
    'Trees_Cover', 'Buildings_Cover', 'Business_Cover', 'Cemetery_Cover', 'Industrial_Cover', 'Infrastructure_Cover', 
    'Parks_Cover', 'Public_Institution_Cover', 'Residence_Cover', 'Sports_Cover', 'Nearest_Jlm_Pole_Distance', 
    'Classification_HPS', 'Classification_LED', 'Roads_Hierarchy_motorway', 'Roads_Hierarchy_primary', 
    'Roads_Hierarchy_residential', 'Roads_Hierarchy_secondary', 'Roads_Hierarchy_tertiary', 'Roads_Hierarchy_trunk'
]

# Ensure the length of the new index matches the number of rows in the DataFrame
if len(new_index) != len(coefficient_df2):
    raise ValueError("The length of the new index does not match the number of rows in the DataFrame.")

# Create the DataFrame with the new index
_df = pd.DataFrame(standardized_df.values, columns=columns_to_convert, index=new_index)

# Define custom colors for each column
colors = ['#bc9b3c', '#e3f54d', '#27e89c', '#ed5cd7']  # Example colors for S1, S2+S4, S3+S5, S1+S2+S3+S4+S5

# Plot the DataFrame as a horizontal bar chart with custom colors
ax = _df.plot.barh(color=colors)

# Set x-axis limits to zoom in on standardized values (optional)
x_min, x_max = -1, 1
plt.xlim(x_min, x_max)

# Create custom legend handles
legend_labels = ['S1: R^2 = 0.1807', 'S2+S4: R^2 = 0.2551', 'S3+S5: R^2 = 0.1979', 'S1+S2+S3+S4+S5: R^2 = 0.1762']
handles = [mpatches.Patch(color=colors[i], label=legend_labels[i]) for i in range(len(legend_labels))]

# Customize the legend with a smaller font size
ax.legend(handles=handles, fontsize='xx-small')

# Add '*' signs from the 'Sign_S1', 'Sign_S2+S4', and 'Sign_S3+S5' columns to the respective bars
sign_columns = ['Sign_S1', 'Sign_S2+S4', 'Sign_S3+S5', 'Sign S1+S2+S3+S4+S5']

for i, row in coefficient_df2.iterrows():
    for j, col in enumerate(columns_to_convert):
        sign_col = sign_columns[j]  # Get the respective sign column
        sign = row[sign_col]  # Get the sign value for this row and column
        
        if sign == '*':  # Check if there's an asterisk
            # Get the standardized bar value for the respective column and index
            bar_value = _df.iloc[i, j]
            
            # Ensure the bar value is valid and within or beyond the xlim range
            if bar_value > x_max:
                ax.text(x_max - 0.04, i + (j - 1) * 0.2, '*', color='black', fontsize=12, verticalalignment='center')
            elif bar_value < x_min:
                ax.text(x_min + 0.02, i + (j - 1) * 0.2, '*', color='black', fontsize=12, verticalalignment='center')
            else:
                ax.text(bar_value + 0.02, i + (j - 1) * 0.2, '*', color='black', fontsize=12, verticalalignment='center')

# Display the plot
plt.title('GLM Coefficient Plot')
plt.xlabel('Coefficient')
plt.ylabel('Variable')
plt.show()

